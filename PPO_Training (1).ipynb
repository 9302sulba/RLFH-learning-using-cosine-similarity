{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is PPO training code used for reward modeling and finetuning"
      ],
      "metadata": {
        "id": "CtvYKZUTMfPm"
      },
      "id": "CtvYKZUTMfPm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b1ea99f-eaf6-4d68-87fa-b44fa31241c2",
      "metadata": {
        "id": "6b1ea99f-eaf6-4d68-87fa-b44fa31241c2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle(\"Results/results_with_similarity.pkl\")\n",
        "df = df.dropna(subset=[\"definition\", \"definition_similarity\"])  # Drop missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a0fa2b-e0c2-4c61-919b-2627f9fc131a",
      "metadata": {
        "id": "35a0fa2b-e0c2-4c61-919b-2627f9fc131a"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Rename columns for PPO compatibility\n",
        "df_for_rl = df.rename(columns={\n",
        "    \"word\": \"query\",                # prompt\n",
        "    \"definition_clean\": \"response\",       # model-generated\n",
        "    \"definition_similarity\": \"reward\"  # cosine similarity\n",
        "})\n",
        "\n",
        "# Drop any rows with missing required fields\n",
        "df_for_rl = df_for_rl[[\"query\", \"response\", \"reward\"]].dropna()\n",
        "\n",
        "# Convert to HuggingFace Dataset\n",
        "reward_dataset = Dataset.from_pandas(df_for_rl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a66daa9-a715-4ae4-a541-7303a3111a77",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1722579f2fe9424bbf48c3ab70b2cb34"
          ]
        },
        "id": "6a66daa9-a715-4ae4-a541-7303a3111a77",
        "outputId": "906209ea-3b23-4b1e-99f7-ff020d909812"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1722579f2fe9424bbf48c3ab70b2cb34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/183 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "def tokenize_prompts(example):\n",
        "    tokens = tokenizer(\n",
        "        example[\"query\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    )\n",
        "    example[\"input_ids\"] = tokens[\"input_ids\"]\n",
        "    example[\"attention_mask\"] = tokens[\"attention_mask\"]\n",
        "    return example\n",
        "\n",
        "tokenized_dataset = reward_dataset.map(tokenize_prompts, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282fadc3-90ee-4e26-989e-0dbcc523ffb9",
      "metadata": {
        "id": "282fadc3-90ee-4e26-989e-0dbcc523ffb9"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = tokenized_dataset.remove_columns([\"query\", \"response\", \"reward\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687e46a0-effb-49bc-b6ba-11e6a14fc8b7",
      "metadata": {
        "id": "687e46a0-effb-49bc-b6ba-11e6a14fc8b7",
        "outputId": "2df247d0-726f-4cda-8987-ac692991f18b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-22 18:27:54.852881: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-22 18:27:54.858857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-22 18:27:54.871703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745368074.893438  260099 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745368074.899995  260099 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1745368074.916088  260099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745368074.916102  260099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745368074.916104  260099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745368074.916105  260099 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-22 18:27:54.924200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimented with two Reward Modeling function"
      ],
      "metadata": {
        "id": "Gsz6rTXnMuHC"
      },
      "id": "Gsz6rTXnMuHC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819c8ab7-444c-4856-929f-f86c4d8f49e0",
      "metadata": {
        "id": "819c8ab7-444c-4856-929f-f86c4d8f49e0"
      },
      "outputs": [],
      "source": [
        "def compute_binary_reward(prompts, responses, threshold=0.85):\n",
        "    rewards = []\n",
        "    for prompt, response in zip(prompts, responses):\n",
        "        wordnet_def = query_to_wordnet_def.get(prompt)\n",
        "        if wordnet_def:\n",
        "            emb1 = embedder.encode(response)\n",
        "            emb2 = embedder.encode(wordnet_def)\n",
        "            sim = cosine_similarity([emb1], [emb2])[0][0]\n",
        "            reward = 1.0 if sim >= threshold else 0.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        rewards.append(reward)\n",
        "    return rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a232438-9556-407c-ad4e-d6312c0dc298",
      "metadata": {
        "id": "5a232438-9556-407c-ad4e-d6312c0dc298"
      },
      "outputs": [],
      "source": [
        "def compute_soft_reward(prompts, responses):\n",
        "    rewards = []\n",
        "    for prompt, response in zip(prompts, responses):\n",
        "        wordnet_def = query_to_wordnet_def.get(prompt)\n",
        "        if wordnet_def:\n",
        "            emb1 = embedder.encode(response)\n",
        "            emb2 = embedder.encode(wordnet_def)\n",
        "            sim = cosine_similarity([emb1], [emb2])[0][0]\n",
        "            reward = float(sim)\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        rewards.append(reward)\n",
        "    return rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf852b5-bd58-4caf-981f-47e8ec030489",
      "metadata": {
        "id": "bdf852b5-bd58-4caf-981f-47e8ec030489"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b081231-e61f-44f0-a03a-8291be2247bb",
      "metadata": {
        "id": "0b081231-e61f-44f0-a03a-8291be2247bb",
        "outputId": "cda80b9f-9b45-4ad0-b59e-65fe6df647fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'HuggingFaceTB/SmolLM2-135M', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
          ]
        }
      ],
      "source": [
        "from trl import AutoModelForCausalLMWithValueHead\n",
        "\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
        "device = next(model.parameters()).device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d390260-7874-4f69-897e-7570ef6ff81e",
      "metadata": {
        "id": "0d390260-7874-4f69-897e-7570ef6ff81e"
      },
      "outputs": [],
      "source": [
        "from trl import PPOConfig\n",
        "\n",
        "config = PPOConfig(\n",
        "    model_name=\"HuggingFaceTB/SmolLM2-135M\",\n",
        "    learning_rate=1.41e-5,\n",
        "    batch_size=8,\n",
        "    mini_batch_size=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c3672b-5cb1-4597-a94d-876fb5517e11",
      "metadata": {
        "id": "27c3672b-5cb1-4597-a94d-876fb5517e11",
        "outputId": "93807bde-82fd-4d93-9b2d-b0caf0fb74ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "from trl import PPOTrainer\n",
        "\n",
        "ppo_trainer = PPOTrainer(\n",
        "    model=model,\n",
        "    config=config,\n",
        "    dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f5c2fe-9fde-4a60-896c-430ecbf6e1b3",
      "metadata": {
        "id": "98f5c2fe-9fde-4a60-896c-430ecbf6e1b3",
        "outputId": "a463472d-6bad-4687-c88d-bb0f608164d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Starting Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/22 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/bsuhome/sulbhamalviya/miniforge3/envs/nlp-env/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1387: UserWarning: The game logs will not be logged because the batch does not contain the keys 'query' and 'response'. \n",
            "  warnings.warn(\n",
            "Epoch 1:   5%|▍         | 1/22 [12:25<4:21:02, 745.85s/it]/bsuhome/sulbhamalviya/miniforge3/envs/nlp-env/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1387: UserWarning: The game logs will not be logged because the batch does not contain the keys 'query' and 'response'. \n",
            "  warnings.warn(\n",
            "Epoch 1:   9%|▉         | 2/22 [24:47<4:07:50, 743.51s/it]/bsuhome/sulbhamalviya/miniforge3/envs/nlp-env/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1387: UserWarning: The game logs will not be logged because the batch does not contain the keys 'query' and 'response'. \n",
            "  warnings.warn(\n",
            "Epoch 1:  14%|█▎        | 3/22 [37:08<3:54:59, 742.10s/it]/bsuhome/sulbhamalviya/miniforge3/envs/nlp-env/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1387: UserWarning: The game logs will not be logged because the batch does not contain the keys 'query' and 'response'. \n",
            "  warnings.warn(\n",
            "Epoch 1:  18%|█▊        | 4/22 [49:23<3:41:52, 739.60s/it]/bsuhome/sulbhamalviya/miniforge3/envs/nlp-env/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1387: UserWarning: The game logs will not be logged because the batch does not contain the keys 'query' and 'response'. \n",
            "  warnings.warn(\n",
            "Epoch 1:  23%|██▎       | 5/22 [1:01:45<3:29:47, 740.46s/it]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# === Generation parameters ===\n",
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"max_new_tokens\": 30,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "query_to_wordnet_def = dict(zip(df[\"word\"], df[\"wordnet_definition\"]))\n",
        "\n",
        "# === Number of epochs ===\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n Starting Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    for step, batch in enumerate(tqdm(ppo_trainer.dataloader, desc=f\"Epoch {epoch+1}\")):\n",
        "        # Remove this to train on full dataset each epoch\n",
        "        # if step >= max_batches:\n",
        "        #     break\n",
        "\n",
        "        query_tensors = batch[\"input_ids\"]\n",
        "        query_tensor_list = list(query_tensors.unbind(dim=0))\n",
        "\n",
        "        response_tensors = ppo_trainer.generate(query_tensor_list, **generation_kwargs)\n",
        "\n",
        "        queries = [tokenizer.decode(q, skip_special_tokens=True) for q in query_tensor_list]\n",
        "        responses = [tokenizer.decode(r.squeeze(), skip_special_tokens=True) for r in response_tensors]\n",
        "\n",
        "        rewards = compute_soft_reward(queries, responses)\n",
        "        rewards = [torch.tensor(r).to(device) for r in rewards]\n",
        "\n",
        "        stats = ppo_trainer.step(query_tensor_list, response_tensors, rewards)\n",
        "        ppo_trainer.log_stats(stats, batch, rewards)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4371e10-a633-41f2-9e77-ddb75ab88f64",
      "metadata": {
        "id": "d4371e10-a633-41f2-9e77-ddb75ab88f64",
        "outputId": "49fe8efe-f119-4fb4-8679-17800f0416db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ppo_finetuned_smol_binary were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Generating definitions from finetuned model: 100%|██████████| 183/183 [3:40:22<00:00, 72.25s/it]  \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from trl import AutoModelForCausalLMWithValueHead\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load WordNet definitions\n",
        "query_to_wordnet_def = dict(zip(df[\"word\"], df[\"wordnet_definition\"]))\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"ppo_finetuned_smol_binary\")\n",
        "\n",
        "# Words to evaluate\n",
        "words = list(query_to_wordnet_def.keys())\n",
        "\n",
        "# Store results\n",
        "finetuned_data = []\n",
        "\n",
        "for word in tqdm(words, desc=\"Generating definitions from finetuned model\"):\n",
        "    prompt = f\"Define {word}\"\n",
        "    tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids=tokens[\"input_ids\"],\n",
        "            attention_mask=tokens[\"attention_mask\"],\n",
        "            max_new_tokens=50,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    definition = tokenizer.decode(output[0], skip_special_tokens=True).replace(prompt, \"\").strip()\n",
        "\n",
        "    # Compute embedding and similarity\n",
        "    def_emb = embedder.encode(definition)\n",
        "    wordnet_def = query_to_wordnet_def[word]\n",
        "    wn_emb = embedder.encode(wordnet_def)\n",
        "    sim_score = cosine_similarity([def_emb], [wn_emb])[0][0]\n",
        "\n",
        "    finetuned_data.append({\n",
        "        \"word\": word,\n",
        "        \"definition\": definition,\n",
        "        \"embedding\": def_emb,\n",
        "        \"wordnet_definition\": wordnet_def,\n",
        "        \"definition_similarity\": sim_score\n",
        "    })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fdcee4-4ae5-42dd-a178-34b1842efa41",
      "metadata": {
        "id": "40fdcee4-4ae5-42dd-a178-34b1842efa41"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame and save\n",
        "df_finetuned = pd.DataFrame(finetuned_data)\n",
        "df_finetuned.to_pickle(\"finetuned_results_with_similarity.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9d0c04-a534-4054-bf7c-f842bd40469b",
      "metadata": {
        "id": "2c9d0c04-a534-4054-bf7c-f842bd40469b",
        "outputId": "64dfd2bd-a922-4a91-c893-df06cf6ee656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('ppo_finetuned_smol_binary/tokenizer_config.json',\n",
              " 'ppo_finetuned_smol_binary/special_tokens_map.json',\n",
              " 'ppo_finetuned_smol_binary/vocab.json',\n",
              " 'ppo_finetuned_smol_binary/merges.txt',\n",
              " 'ppo_finetuned_smol_binary/added_tokens.json',\n",
              " 'ppo_finetuned_smol_binary/tokenizer.json')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"ppo_finetuned_smol_binary\")\n",
        "tokenizer.save_pretrained(\"ppo_finetuned_smol_binary\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SmIEU5BPPv0"
      },
      "id": "9SmIEU5BPPv0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-env",
      "language": "python",
      "name": "nlp-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}